{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade: Perceptron - Petróleo\n",
    "\n",
    "**INSTITUTO FEDERAL DE MINAS GERAIS**\n",
    "*Departamento de Engenharia e Computação*\n",
    "\n",
    "**Professor:** Ciniro Nametala  \n",
    "**Aluno:** Emanuel Rocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1759499292840,
     "user": {
      "displayName": "Astronomic Cuts",
      "userId": "07519333501481638317"
     },
     "user_tz": 180
    },
    "id": "EnKWDiO9w1QU"
   },
   "outputs": [],
   "source": [
    "#importacao de pacotes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1759499292850,
     "user": {
      "displayName": "Astronomic Cuts",
      "userId": "07519333501481638317"
     },
     "user_tz": 180
    },
    "id": "fyty813L4PYu"
   },
   "outputs": [],
   "source": [
    "#funcao degau bipolar\n",
    "def bipolar(u):\n",
    "    return np.where(u >= 0, 1, -1)\n",
    "#funcao pra classifica a amostra com base na rede ja treinada\n",
    "def previsao(w,x):\n",
    "  u=np.dot(w.T,x)\n",
    "  return bipolar(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1759499292869,
     "user": {
      "displayName": "Astronomic Cuts",
      "userId": "07519333501481638317"
     },
     "user_tz": 180
    },
    "id": "_exRHjls744N",
    "outputId": "7e4b538a-c4d1-4f85-b491-7c18f947725e"
   },
   "outputs": [],
   "source": [
    "#PASSO 1: OBTER O CONJUNTO DE AMOSTRAS DE TREINAMENTO X\n",
    "dados = pd.read_csv(\"tabela_treino.csv\", sep=\";\")\n",
    "nump=5\n",
    "#quantidade de elementos na amostra\n",
    "n_amostras=dados.shape[0]\n",
    "#quantidade variaveis de entrada(subrair a coluna de tipo)\n",
    "n_variaveis=dados.shape[1]-1\n",
    "#separando os dados contendo apenas as variaveis de entrada\n",
    "x=dados.iloc[:,1:n_variaveis].values\n",
    "#print(x)\n",
    "n_variaveis=x.shape[1]\n",
    "#print(n_variaveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1759499292905,
     "user": {
      "displayName": "Astronomic Cuts",
      "userId": "07519333501481638317"
     },
     "user_tz": 180
    },
    "id": "Fr0xMzF49c_g",
    "outputId": "3b4fd904-5f6a-4a6b-f189-eceffd5c5e2b"
   },
   "outputs": [],
   "source": [
    "#inserindo o bias\n",
    "bias=np.ones((n_amostras,1))*-1\n",
    "x=np.hstack((x,bias))\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1759499292920,
     "user": {
      "displayName": "Astronomic Cuts",
      "userId": "07519333501481638317"
     },
     "user_tz": 180
    },
    "id": "Q0QrrR9d_I8I",
    "outputId": "6e01184c-5e8b-4406-ac47-5c819c497a1a"
   },
   "outputs": [],
   "source": [
    "#PASSO 2: DO VETOR DE SAIDAS Y, ASSOCIAR A SAIDA ESPERADA Y PARA CADA X\n",
    "y=dados.iloc[:,-1].values\n",
    "#print(y)\n",
    "#contar quantas amostras de cada classe existem no dataset\n",
    "#print(f\"-1: {(y==-1).sum()}\")\n",
    "#print(f\"1: {(y==1).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)  Treine uma RNA com arquitetura Perceptron cinco vezes (T1 até T5), sempre iniciando o vetor de pesos w com valores aleatórios entre 0 e 1. Garanta que em cada uma das cinco tentativas de treinamento os pesos iniciais do vetor w sejam diferentes. Garanta que o erro seja baixo testando diferentes números de épocas e observando a convergência do erro médio. Após definir um total de épocas suficiente, mantenha a mesma quantidade de épocas para todos os cinco treinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1759499292930,
     "user": {
      "displayName": "Astronomic Cuts",
      "userId": "07519333501481638317"
     },
     "user_tz": 180
    },
    "id": "veVeRQI5AAaP",
    "outputId": "e24be168-6957-45c2-d4d4-da2d062fe171"
   },
   "outputs": [],
   "source": [
    "#INICIALIZAR OS VETORES DE PESOS W COM VALORES ALEATORIOS\n",
    "pesos = [np.random.rand(n_variaveis + 1) for i in range(nump)]\n",
    "pesos_iniciais=[w.copy() for w in pesos]\n",
    "#for i in range(nump):\n",
    "#   print(f\"w{i+1}: {pesos[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1759499292933,
     "user": {
      "displayName": "Astronomic Cuts",
      "userId": "07519333501481638317"
     },
     "user_tz": 180
    },
    "id": "QyfZNC-EAmTH"
   },
   "outputs": [],
   "source": [
    "#DEFINIR A TAXA DE APRENDIZAGEM COM VALOR ENTRE 0 E 1 E TOLERANCIA\n",
    "eta=0.01\n",
    "tolerancia=0.02\n",
    "\n",
    "#SETAR O ERRO INICIAL E CRIAR O VETOR QUE PRA ARMAZENAR OS ERROS DAS EPOCAS\n",
    "erro_medio=[tolerancia+1]*nump\n",
    "erro_epocas = [[] for i in range(nump)]\n",
    "epocas = [0] * nump\n",
    "max_epocas=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 90,
     "status": "ok",
     "timestamp": 1759499293022,
     "user": {
      "displayName": "Astronomic Cuts",
      "userId": "07519333501481638317"
     },
     "user_tz": 180
    },
    "id": "mIS0hyUkC2RR"
   },
   "outputs": [],
   "source": [
    "for idx in range(nump):\n",
    "    erro_medio = tolerancia + 1\n",
    "    epoca = 0\n",
    "    w = pesos[idx]\n",
    "\n",
    "    while erro_medio >= tolerancia and epoca < max_epocas:\n",
    "        epoca += 1\n",
    "        erro_atual = 0\n",
    "        indices = np.random.permutation(n_amostras)\n",
    "\n",
    "        for i in indices:\n",
    "            xi = x[i, :]\n",
    "            u = np.dot(w.T, xi)\n",
    "            yhat = bipolar(u)\n",
    "            e = y[i] - yhat\n",
    "            w += eta * e * xi\n",
    "            erro_atual += np.abs(e)\n",
    "\n",
    "        erro_medio = erro_atual / n_amostras\n",
    "        erro_epocas[idx].append(erro_medio)\n",
    "\n",
    "    pesos[idx] = w\n",
    "    epocas[idx] = epoca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1759499293271,
     "user": {
      "displayName": "Astronomic Cuts",
      "userId": "07519333501481638317"
     },
     "user_tz": 180
    },
    "id": "T9EhuOnOQqcJ",
    "outputId": "e760ceed-35e4-45dc-ccc5-e9459333abc3"
   },
   "outputs": [],
   "source": [
    "#for idx in range(nump):    \n",
    "#    plt.figure(figsize=(4,4))\n",
    "#    plt.plot(erro_epocas[idx])\n",
    "#    plt.title(f'Convergência do erro - Perceptron {idx+1}')\n",
    "#    plt.xlabel('Épocas')\n",
    "#    plt.ylabel('Erro médio')\n",
    "#    plt.grid(True)\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo as novas amostras pra classificar\n",
    "dados_classif = pd.read_csv(\"tabela_classificacao.csv\", sep=\";\")\n",
    "x_classif = dados_classif.iloc[:, 1:n_variaveis+1].values\n",
    "bias_classif = np.ones((x_classif.shape[0], 1)) * -1\n",
    "x_classif = np.hstack((x_classif, bias_classif))\n",
    "#print(x_classif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Registre os resultados dos pesos antes e depois dos treinos, em cada um dos cinco treinos conforme a Tabela 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino      w0_ini    w1_ini    w2_ini    w3_ini    w0_fim    w1_fim    w2_fim    w3_fim\n",
      "Treino 1    0.4776    0.6744    0.5422    0.2438    0.3936    0.9455   -0.1735   -0.7562\n",
      "Treino 2    0.2845    0.1454    0.8351    0.7357    0.3726    0.7839   -0.0934   -0.7843\n",
      "Treino 3    0.3015    0.2410    0.8604    0.5647    0.3692    0.8872   -0.0399   -0.7353\n",
      "Treino 4    0.7700    0.0199    0.1737    0.2174    0.3360    0.8703   -0.2954   -0.6626\n",
      "Treino 5    0.4941    0.4191    0.8865    0.1149    0.3718    0.8818   -0.1834   -0.6051\n"
     ]
    }
   ],
   "source": [
    "num_pesos = n_variaveis + 1\n",
    "cabecalho = \"Treino\".ljust(8)\n",
    "for i in range(num_pesos):\n",
    "    cabecalho += f\"w{i}_ini\".rjust(10)\n",
    "for i in range(num_pesos):\n",
    "    cabecalho += f\"w{i}_fim\".rjust(10)\n",
    "print(cabecalho)\n",
    "\n",
    "for idx in range(nump):\n",
    "    linha = f\"{'Treino '+str(idx+1)}\".ljust(8)\n",
    "    # pesos iniciais\n",
    "    for w in pesos_iniciais[idx]:\n",
    "        linha += f\"{w:10.4f}\"\n",
    "    # pesos finais\n",
    "    for w in pesos[idx]:\n",
    "        linha += f\"{w:10.4f}\"\n",
    "    print(linha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Após o treinamento dos modelos, aplique-os separadamente na classificação das amostras de óleo da tabela abaixo (arquivo tabela_classificacao.csv). Anote na Tabela 2 os resultados das saídas (classes) para cada amostra e para cada modelo treinado (T1 até T5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tabela de Classificação:\n",
      "Amostra           x1        x2        x3        T1        T2        T3        T4        T5\n",
      "1            -0.3665    0.0620    5.9891        -1         1         1        -1        -1\n",
      "2            -0.7842    1.1267    5.5912         1         1         1        -1         1\n",
      "3             0.3012    0.5611    5.8234         1         1         1        -1         1\n",
      "4             0.7757    1.0648    8.0677         1         1         1        -1         1\n",
      "5             0.1570    0.8028    6.3040         1         1         1        -1         1\n",
      "6            -0.7014    1.0316    3.6005         1         1         1         1         1\n",
      "7             0.3748    0.1536    6.1537        -1         1         1        -1        -1\n",
      "8            -0.6920    0.9404    4.4058         1         1         1        -1         1\n",
      "9            -1.3970    0.7141    4.9263         1         1         1        -1        -1\n",
      "10           -1.8842   -0.2805    1.2548        -1        -1        -1        -1        -1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTabela de Classificação:\")\n",
    "cabecalho = \"Amostra\".ljust(10) + \"x1\".rjust(10) + \"x2\".rjust(10) + \"x3\".rjust(10)\n",
    "for i in range(nump):\n",
    "    cabecalho += f\"T{i+1}\".rjust(10)\n",
    "print(cabecalho)\n",
    "\n",
    "# coloca cada peso de cada modelo pra cada amostra\n",
    "for j in range(x_classif.shape[0]):\n",
    "    # Amostra + valores de entrada\n",
    "    linha = f\"{str(j+1)}\".ljust(10)\n",
    "    for valor in x_classif[j, :n_variaveis]:  # pega só x1, x2, x3 (sem o bias)\n",
    "        linha += f\"{valor:10.4f}\"\n",
    "\n",
    "    # Saídas dos modelos\n",
    "    for i in range(nump):\n",
    "        w = pesos[i]\n",
    "        y_pred = previsao(w, x_classif[j])\n",
    "        linha += f\"{y_pred:10}\"\n",
    "    print(linha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Qual foi sua taxa de acerto percentual para cada modelo?\n",
    "\n",
    "> testei com a propria tabela treino porque a de classificacao não tem os resultados pra poder comparar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto percentual para o modelo 1: 63.33%\n",
      "Taxa de acerto percentual para o modelo 2: 46.67%\n",
      "Taxa de acerto percentual para o modelo 3: 46.67%\n",
      "Taxa de acerto percentual para o modelo 4: 63.33%\n",
      "Taxa de acerto percentual para o modelo 5: 66.67%\n"
     ]
    }
   ],
   "source": [
    "yhat = [np.zeros(n_amostras) for _ in range(nump)]\n",
    "\n",
    "for idx in range(nump):\n",
    "    for i in range(n_amostras):\n",
    "        yhat[idx][i] = previsao(pesos[idx], x[i,:])\n",
    "for idx in range(nump):\n",
    "    acuracia = (np.sum(yhat[idx] == y) / n_amostras) * 100\n",
    "    print(f\"Taxa de acerto percentual para o modelo {idx+1}: {acuracia:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Qual o efeito de aumentar ou diminuir o número de épocas na qualidade dos resultados?\n",
    "\n",
    "> Não tem efeito algum, rodar com 500 ou 1 milhão de epocas no máximo não muda nada, a taxa de acerto continua na mesma faixa e as vezes com os mesmos valores.\n",
    "\n",
    "### 6) Qual o efeito de aumentar ou diminuir a taxa de aprendizagem na qualidade dos resultados?\n",
    "\n",
    "> Não tem efeito nenhum na qualidade dos resultados, os modelos sempre ficam acima de 0.2 de erro, mas no resultado o valor não afeta.\n",
    "\n",
    "### 7) As classes neste problema são linearmente separáveis?\n",
    "\n",
    "> Não, mesmo plotando o gráfico 3d não e possivel ver como um plano poderia separar corretamente as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colors = ['red' if yi == -1 else 'blue' for yi in y]\n",
    "#fig = go.Figure()\n",
    "#fig.add_trace(go.Scatter3d(\n",
    "#    x=x[:, 0],\n",
    "#    y=x[:, 1],\n",
    "#    z=x[:, 2],\n",
    "#    mode='markers',\n",
    "#    marker=dict(\n",
    "#        size=6,\n",
    "#        color=colors,\n",
    "#        opacity=0.8,\n",
    "#        line=dict(width=1, color='white')\n",
    "#    ),\n",
    "#    name='Amostras'\n",
    "#))\n",
    "#fig.update_layout(\n",
    "#    title='Distribuição das Amostras no Espaço 3D',\n",
    "#    scene=dict(\n",
    "#        xaxis_title='x1',\n",
    "#        yaxis_title='x2',\n",
    "#        zaxis_title='x3'\n",
    "#    ),\n",
    "#    width=800,\n",
    "#    height=600\n",
    "#)\n",
    "#fig.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMTLPmIVjCWuQmz2AqWjA1v",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b76ca7df",
   "metadata": {},
   "source": [
    "### Tópicos Especiais em Inteligência Artificial: Redes Neurais Artificiais\n",
    "### Professor Ciniro Nametala - IFMG\n",
    "\n",
    "## Geração de imagens falsas com Deep Convolutional Generative Adversarial Networks (DCGAN)\n",
    "\n",
    "Neste trabalho vamos utilizar o *dataset Fashion-MNIST* disponível no [repositório oficial do Zalando Research](https://github.com/zalandoresearch/fashion-mnist). Este é um conjunto de dados composto por 70.000 imagens em escala de cinza com resolução 28×28 pixels, divididas em 10 classes de roupas e acessórios. O objetivo é treinar uma GAN (Generative Adversarial Network) capaz de **gerar imagens novas de roupas** que não existem no dataset original.\n",
    "\n",
    "**Classes do dataset:**\n",
    "| Label | Classe |\n",
    "|-------|--------|\n",
    "| 0 | Camiseta |\n",
    "| 1 | Calça |\n",
    "| 2 | Suéter |\n",
    "| 3 | Vestido |\n",
    "| 4 | Casaco |\n",
    "| 5 | Sandália |\n",
    "| 6 | Camisa |\n",
    "| 7 | Tênis |\n",
    "| 8 | Bolsa |\n",
    "| 9 | Bota |\n",
    "\n",
    "**Arquitetura GAN:**\n",
    "\n",
    "Uma GAN é composta por duas redes neurais que competem entre si:\n",
    "- **Gerador (G):** Recebe um vetor de ruído aleatório e gera imagens falsas\n",
    "- **Discriminador (D):** Recebe imagens (reais ou falsas) e classifica como real ou falsa\n",
    "\n",
    "O treinamento é um jogo de soma zero: o Gerador tenta enganar o Discriminador, enquanto o Discriminador tenta não ser enganado. Ao final, o Gerador aprende a criar imagens realistas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31713402",
   "metadata": {},
   "source": [
    "## 1. Preparação do ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "### 1.1 Configurações de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47771a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#funcao para deixar o jupyter com celulas preenchendo toda a tela\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6g7h8",
   "metadata": {},
   "source": [
    "### 1.2 Importação de pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae9d810f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rocha\\anaconda3\\envs\\tf310\\lib\\site-packages\\pygame\\pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.19)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "#importacao de bibliotecas\n",
    "\n",
    "#para exportar o requirements\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#bibliotecas para trabalhar com dados e graficos\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#biblioteca para gerar gif\n",
    "import imageio\n",
    "\n",
    "#biblioteca para tocar sons\n",
    "import pygame\n",
    "\n",
    "from numba import cuda\n",
    "\n",
    "#bibliotecas para deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, Dropout\n",
    "#se estiver usando windows ou linux comente a linha a seguir e descomente a próxima\n",
    "#from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "#biblioteca para barra de progresso\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i9j0k1l2",
   "metadata": {},
   "source": [
    "### 1.3 Verificando versões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9d279e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.13.1\n",
      "keras: 2.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "print('tensorflow:', tf.__version__)\n",
    "print('keras:', keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m3n4o5p6",
   "metadata": {},
   "source": [
    "### 1.4 Checagem de GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4a1d9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.13.1\n",
      "gpu disponivel: False\n",
      "gpu: []\n"
     ]
    }
   ],
   "source": [
    "#checagem de GPU\n",
    "print('tensorflow:', tf.__version__)\n",
    "print('gpu disponivel:', len(tf.config.list_physical_devices('GPU')) > 0)\n",
    "print('gpu:', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39ef36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exportacao do requirements.txt\n",
    "def exportarRequirements():\n",
    "    try:\n",
    "        result = subprocess.run([sys.executable, '-m', 'pip', 'freeze'], \n",
    "                                capture_output=True, \n",
    "                                text=True, \n",
    "                                check=True)\n",
    "\n",
    "        with open('requirements.txt', 'w') as f:\n",
    "            f.write(result.stdout)\n",
    "\n",
    "        print('requirements.txt exportado com sucesso')\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f'erro ao exportar requirements: {e}')\n",
    "\n",
    "exportarRequirements()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6852f",
   "metadata": {},
   "source": [
    "## 2. Configurações do experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01d3501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "#CONFIGURACOES DE VISUALIZACAO\n",
    "#------------------------------\n",
    "\n",
    "#exibir grade de imagens geradas ao final do treino\n",
    "show_generated_grid = True\n",
    "\n",
    "#salvar imagens durante o treino (a cada n epocas)\n",
    "save_evolution_images = True\n",
    "\n",
    "#gerar gif animado da evolucao do treinamento\n",
    "generate_evolution_gif = True\n",
    "\n",
    "#exibir interpolacao no espaco latente\n",
    "show_latent_interpolation = True\n",
    "\n",
    "#------------------------------\n",
    "#CONFIGURACOES DE TREINAMENTO\n",
    "#------------------------------\n",
    "\n",
    "#treinar um novo modelo ou carregar existente\n",
    "new_model = False\n",
    "\n",
    "#numero de epocas de treinamento\n",
    "epochs = 100\n",
    "\n",
    "#tamanho do batch\n",
    "batch_size = 128\n",
    "\n",
    "#dimensao do espaco latente (vetor de ruido)\n",
    "latent_dim = 100\n",
    "\n",
    "#intervalo para salvar imagens durante treino\n",
    "save_interval = 10\n",
    "\n",
    "#learning rate\n",
    "learning_rate = 0.0002\n",
    "\n",
    "#beta1 para adam\n",
    "beta1 = 0.5\n",
    "\n",
    "#------------------------------\n",
    "#CONFIGURACOES DE ARQUIVOS\n",
    "#------------------------------\n",
    "\n",
    "#nome do modelo\n",
    "model_name = 'dcgan_fashion_mnist'\n",
    "\n",
    "#pasta para salvar imagens da evolucao\n",
    "evolution_folder = 'evolution_images'\n",
    "\n",
    "#pasta para salvar modelos\n",
    "models_folder = 'models'\n",
    "\n",
    "#criar pastas se nao existirem\n",
    "os.makedirs(evolution_folder, exist_ok=True)\n",
    "os.makedirs(models_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q7r8s9t0",
   "metadata": {},
   "source": [
    "## 3. Importação de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67d36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregando o dataset fashion mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "#nomes das classes\n",
    "class_names = ['Camiseta', 'Calca', 'Sueter', 'Vestido', 'Casaco',\n",
    "                'Sandalia', 'Camisa', 'Tenis', 'Bolsa', 'Bota']\n",
    "\n",
    "print(f'x_train shape: {x_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'x_test shape: {x_test.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u1v2w3x4",
   "metadata": {},
   "source": [
    "## 4. Análise de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y5z6a7b8",
   "metadata": {},
   "source": [
    "### 4.1 Visualização das amostras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b57e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizando algumas amostras do dataset\n",
    "fig, axes = plt.subplots(2, 5, figsize=(8, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    #encontrar primeira imagem de cada classe\n",
    "    idx = np.where(y_train == i)[0][0]\n",
    "    axes[i].imshow(x_train[idx], cmap='gray')\n",
    "    axes[i].set_title(class_names[i])\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Amostras do Fashion-MNIST (uma por classe)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2",
   "metadata": {},
   "source": [
    "### 4.2 Sumarização estatística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stats01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estatisticas do dataset\n",
    "print('='*50)\n",
    "print('ESTATISTICAS DO DATASET')\n",
    "print('='*50)\n",
    "print(f'total de amostras de treino: {len(x_train)}')\n",
    "print(f'total de amostras de teste: {len(x_test)}')\n",
    "print(f'dimensoes da imagem: {x_train.shape[1]}x{x_train.shape[2]}')\n",
    "print(f'valor minimo dos pixels: {x_train.min()}')\n",
    "print(f'valor maximo dos pixels: {x_train.max()}')\n",
    "print(f'tipo de dado: {x_train.dtype}')\n",
    "print('='*50)\n",
    "\n",
    "#distribuicao das classes\n",
    "print('\\nDISTRIBUICAO DAS CLASSES (treino):')\n",
    "for i in range(10):\n",
    "    count = np.sum(y_train == i)\n",
    "    print(f'{class_names[i]}: {count} ({100*count/len(y_train):.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g3h4i5j6",
   "metadata": {},
   "source": [
    "### 4.3 Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preproc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processamento: normalizar para [-1, 1] (padrao para GANs com tanh)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train = (x_train - 127.5) / 127.5\n",
    "\n",
    "#adicionar dimensao do canal (28, 28) -> (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "\n",
    "print(f'shape apos pre-processamento: {x_train.shape}')\n",
    "print(f'valor minimo: {x_train.min()}')\n",
    "print(f'valor maximo: {x_train.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k7l8m9n0",
   "metadata": {},
   "source": [
    "## 5. Treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o1p2q3r4",
   "metadata": {},
   "source": [
    "### 5.1 Construção do Gerador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gen01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcao para construir o gerador\n",
    "def construirGerador(latent_dim):\n",
    "    #entrada: vetor de ruido\n",
    "    noise_input = Input(shape=(latent_dim,), name='noise_input')\n",
    "    \n",
    "    #camada densa inicial: projeta para 7x7x256\n",
    "    x = Dense(7 * 7 * 256, use_bias=False)(noise_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Reshape((7, 7, 256))(x)\n",
    "    \n",
    "    #conv transposta 1: 7x7x256 -> 7x7x128\n",
    "    x = Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    #conv transposta 2: 7x7x128 -> 14x14x64\n",
    "    x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    #conv transposta 3: 14x14x64 -> 28x28x1\n",
    "    output = Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)\n",
    "    \n",
    "    model = Model(noise_input, output, name='gerador')\n",
    "    return model\n",
    "\n",
    "#construir gerador\n",
    "gerador = construirGerador(latent_dim)\n",
    "print('gerador construido com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s5t6u7v8",
   "metadata": {},
   "source": [
    "### 5.2 Construção do Discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcao para construir o discriminador\n",
    "def construirDiscriminador(img_shape):\n",
    "    #entrada: imagem\n",
    "    img_input = Input(shape=img_shape, name='img_input')\n",
    "    \n",
    "    #conv 1: 28x28x1 -> 14x14x64\n",
    "    x = Conv2D(64, (5, 5), strides=(2, 2), padding='same')(img_input)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    #conv 2: 14x14x64 -> 7x7x128\n",
    "    x = Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    #flatten e saida\n",
    "    x = Flatten()(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(img_input, output, name='discriminador')\n",
    "    return model\n",
    "\n",
    "#construir discriminador\n",
    "img_shape = (28, 28, 1)\n",
    "discriminador = construirDiscriminador(img_shape)\n",
    "print('discriminador construido com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w9x0y1z2",
   "metadata": {},
   "source": [
    "### 5.3 Construção da GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gan01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compilar discriminador\n",
    "opt_disc = Adam(learning_rate=learning_rate, beta_1=beta1)\n",
    "discriminador.compile(loss='binary_crossentropy', optimizer=opt_disc, metrics=['accuracy'])\n",
    "\n",
    "#para treinar o gerador, congelamos o discriminador\n",
    "discriminador.trainable = False\n",
    "\n",
    "#construir modelo combinado (gan)\n",
    "noise_input = Input(shape=(latent_dim,))\n",
    "img_gerada = gerador(noise_input)\n",
    "validade = discriminador(img_gerada)\n",
    "\n",
    "gan = Model(noise_input, validade, name='gan')\n",
    "\n",
    "#compilar gan\n",
    "opt_gan = Adam(learning_rate=learning_rate, beta_1=beta1)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=opt_gan)\n",
    "\n",
    "print('gan construida com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6",
   "metadata": {},
   "source": [
    "### 5.4 Inspecionando os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insp01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumario do gerador\n",
    "print('='*60)\n",
    "print('GERADOR')\n",
    "print('='*60)\n",
    "gerador.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insp02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumario do discriminador\n",
    "print('='*60)\n",
    "print('DISCRIMINADOR')\n",
    "print('='*60)\n",
    "discriminador.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insp03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumario da gan\n",
    "print('='*60)\n",
    "print('GAN (MODELO COMBINADO)')\n",
    "print('='*60)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insp04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot do gerador\n",
    "plot_model(gerador, to_file='gerador_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insp05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot do discriminador\n",
    "plot_model(discriminador, to_file='discriminador_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8g9h0",
   "metadata": {},
   "source": [
    "### 5.5 Funções auxiliares de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aux01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcao para salvar grade de imagens geradas\n",
    "def salvarGradeImagens(epoch, gerador, latent_dim, examples=16, dim=(4, 4), figsize=(6, 6)):\n",
    "    noise = np.random.normal(0, 1, (examples, latent_dim))\n",
    "    gen_imgs = gerador.predict(noise, verbose=0)\n",
    "    \n",
    "    #desnormalizar de [-1, 1] para [0, 1]\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "    \n",
    "    fig, axes = plt.subplots(dim[0], dim[1], figsize=figsize)\n",
    "    cnt = 0\n",
    "    for i in range(dim[0]):\n",
    "        for j in range(dim[1]):\n",
    "            axes[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axes[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    \n",
    "    plt.suptitle(f'Epoca {epoch}', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_evolution_images:\n",
    "        plt.savefig(f'{evolution_folder}/epoca_{epoch:04d}.png')\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aux02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcao para gerar ruido latente\n",
    "def gerarRuido(batch_size, latent_dim):\n",
    "    return np.random.normal(0, 1, (batch_size, latent_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i1j2k3l4",
   "metadata": {},
   "source": [
    "### 5.6 Otimização do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if new_model:\n",
    "    #listas para armazenar historico de losses\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    d_accs = []\n",
    "    \n",
    "    #labels para treino\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = np.zeros((batch_size, 1))\n",
    "    \n",
    "    #numero de batches por epoca\n",
    "    n_batches = x_train.shape[0] // batch_size\n",
    "    \n",
    "    print('='*60)\n",
    "    print('INICIANDO TREINAMENTO')\n",
    "    print('='*60)\n",
    "    print(f'epocas: {epochs}')\n",
    "    print(f'batch size: {batch_size}')\n",
    "    print(f'batches por epoca: {n_batches}')\n",
    "    print(f'latent dim: {latent_dim}')\n",
    "    print('='*60)\n",
    "    \n",
    "    #salvar imagem inicial (epoca 0)\n",
    "    salvarGradeImagens(0, gerador, latent_dim)\n",
    "    \n",
    "    #loop de treinamento\n",
    "    for epoch in tqdm(range(1, epochs + 1), desc='Treinando'):\n",
    "        epoch_d_loss = 0\n",
    "        epoch_g_loss = 0\n",
    "        epoch_d_acc = 0\n",
    "        \n",
    "        for batch in range(n_batches):\n",
    "            #---------------------\n",
    "            #treinar discriminador\n",
    "            #---------------------\n",
    "            \n",
    "            #selecionar batch de imagens reais\n",
    "            idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "            real_imgs = x_train[idx]\n",
    "            \n",
    "            #gerar imagens falsas\n",
    "            noise = gerarRuido(batch_size, latent_dim)\n",
    "            fake_imgs = gerador.predict(noise, verbose=0)\n",
    "            \n",
    "            #treinar discriminador em imagens reais e falsas\n",
    "            d_loss_real = discriminador.train_on_batch(real_imgs, real_labels)\n",
    "            d_loss_fake = discriminador.train_on_batch(fake_imgs, fake_labels)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            #---------------------\n",
    "            #treinar gerador\n",
    "            #---------------------\n",
    "            \n",
    "            #gerar novo ruido\n",
    "            noise = gerarRuido(batch_size, latent_dim)\n",
    "            \n",
    "            #treinar gerador (queremos que discriminador classifique como real)\n",
    "            g_loss = gan.train_on_batch(noise, real_labels)\n",
    "            \n",
    "            epoch_d_loss += d_loss[0]\n",
    "            epoch_g_loss += g_loss\n",
    "            epoch_d_acc += d_loss[1]\n",
    "        \n",
    "        #media das losses da epoca\n",
    "        epoch_d_loss /= n_batches\n",
    "        epoch_g_loss /= n_batches\n",
    "        epoch_d_acc /= n_batches\n",
    "        \n",
    "        d_losses.append(epoch_d_loss)\n",
    "        g_losses.append(epoch_g_loss)\n",
    "        d_accs.append(epoch_d_acc)\n",
    "        \n",
    "        #salvar imagens a cada save_interval epocas\n",
    "        if epoch % save_interval == 0:\n",
    "            salvarGradeImagens(epoch, gerador, latent_dim)\n",
    "            print(f'epoca {epoch}/{epochs} - d_loss: {epoch_d_loss:.4f} - g_loss: {epoch_g_loss:.4f} - d_acc: {epoch_d_acc:.4f}')\n",
    "    \n",
    "    #salvar modelos\n",
    "    gerador.save(f'{models_folder}/{model_name}_gerador.h5')\n",
    "    discriminador.save(f'{models_folder}/{model_name}_discriminador.h5')\n",
    "    \n",
    "    #salvar historico\n",
    "    history = {'d_loss': d_losses, 'g_loss': g_losses, 'd_acc': d_accs}\n",
    "    np.save(f'{models_folder}/{model_name}_history.npy', history)\n",
    "    \n",
    "    print('\\nmodelos salvos com sucesso')\n",
    "\n",
    "else:\n",
    "    #carregar modelos existentes\n",
    "    gerador = load_model(f'{models_folder}/{model_name}_gerador.h5')\n",
    "    discriminador = load_model(f'{models_folder}/{model_name}_discriminador.h5')\n",
    "    history = np.load(f'{models_folder}/{model_name}_history.npy', allow_pickle=True).item()\n",
    "    d_losses = history['d_loss']\n",
    "    g_losses = history['g_loss']\n",
    "    d_accs = history['d_acc']\n",
    "    print('modelos carregados com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m5n6o7p8",
   "metadata": {},
   "source": [
    "### 5.7 Avaliação da evolução do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot das curvas de loss\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "#grafico de losses\n",
    "ax1.plot(d_losses, label='discriminador', alpha=0.8)\n",
    "ax1.plot(g_losses, label='gerador', alpha=0.8)\n",
    "ax1.set_xlabel('Epoca')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Evolucao das Losses')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "#grafico de acuracia do discriminador\n",
    "ax2.plot(d_accs, label='discriminador', color='green', alpha=0.8)\n",
    "ax2.axhline(y=0.5, color='r', linestyle='--', label='equilibrio (0.5)')\n",
    "ax2.set_xlabel('Epoca')\n",
    "ax2.set_ylabel('Acuracia')\n",
    "ax2.set_title('Acuracia do Discriminador')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q9r0s1t2",
   "metadata": {},
   "source": [
    "## 6. Testando as gerações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u3v4w5x6",
   "metadata": {},
   "source": [
    "### 6.1 Gerando imagens com o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_generated_grid:\n",
    "    #gerar grade maior de imagens\n",
    "    n_examples = 25\n",
    "    noise = gerarRuido(n_examples, latent_dim)\n",
    "    gen_imgs = gerador.predict(noise, verbose=0)\n",
    "    \n",
    "    #desnormalizar\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "    \n",
    "    #plot\n",
    "    fig, axes = plt.subplots(5, 5, figsize=(8, 5))\n",
    "    cnt = 0\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            axes[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axes[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    \n",
    "    plt.suptitle('Imagens Geradas pela DCGAN', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y7z8a9b0",
   "metadata": {},
   "source": [
    "### 6.2 Interpolação no espaço latente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interp01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_latent_interpolation:\n",
    "    #funcao para interpolar entre dois pontos no espaco latente\n",
    "    def interpolarEspacoLatente(gerador, latent_dim, n_steps=10):\n",
    "        #gerar dois pontos aleatorios\n",
    "        z1 = np.random.normal(0, 1, (1, latent_dim))\n",
    "        z2 = np.random.normal(0, 1, (1, latent_dim))\n",
    "        \n",
    "        #interpolar\n",
    "        ratios = np.linspace(0, 1, n_steps)\n",
    "        vectors = [(1 - ratio) * z1 + ratio * z2 for ratio in ratios]\n",
    "        vectors = np.vstack(vectors)\n",
    "        \n",
    "        #gerar imagens\n",
    "        gen_imgs = gerador.predict(vectors, verbose=0)\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        return gen_imgs\n",
    "    \n",
    "    #gerar interpolacao\n",
    "    n_steps = 10\n",
    "    interp_imgs = interpolarEspacoLatente(gerador, latent_dim, n_steps)\n",
    "    \n",
    "    #plot\n",
    "    fig, axes = plt.subplots(1, n_steps, figsize=(14, 2))\n",
    "    for i in range(n_steps):\n",
    "        axes[i].imshow(interp_imgs[i, :, :, 0], cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Interpolacao no Espaco Latente', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interp02",
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_latent_interpolation:\n",
    "    #multiplas interpolacoes\n",
    "    n_interpolations = 5\n",
    "    n_steps = 10\n",
    "    \n",
    "    fig, axes = plt.subplots(n_interpolations, n_steps, figsize=(12, 6))\n",
    "    \n",
    "    for row in range(n_interpolations):\n",
    "        interp_imgs = interpolarEspacoLatente(gerador, latent_dim, n_steps)\n",
    "        for col in range(n_steps):\n",
    "            axes[row, col].imshow(interp_imgs[col, :, :, 0], cmap='gray')\n",
    "            axes[row, col].axis('off')\n",
    "    \n",
    "    plt.suptitle('Multiplas Interpolacoes no Espaco Latente', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4",
   "metadata": {},
   "source": [
    "### 6.3 GIF da evolução do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gif01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_evolution_gif and save_evolution_images:\n",
    "    #criar gif da evolucao\n",
    "    images = []\n",
    "    filenames = sorted([f for f in os.listdir(evolution_folder) if f.endswith('.png')])\n",
    "    \n",
    "    for filename in filenames:\n",
    "        images.append(imageio.imread(f'{evolution_folder}/{filename}'))\n",
    "    \n",
    "    #salvar gif\n",
    "    gif_path = f'{evolution_folder}/{model_name}_evolucao.gif'\n",
    "    imageio.mimsave(gif_path, images, fps=2)\n",
    "    print(f'gif salvo em: {gif_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparacao: imagens reais vs geradas\n",
    "fig, axes = plt.subplots(2, 8, figsize=(12, 4))\n",
    "\n",
    "#imagens reais\n",
    "idx = np.random.randint(0, x_train.shape[0], 8)\n",
    "for i in range(8):\n",
    "    axes[0, i].imshow((x_train[idx[i], :, :, 0] + 1) / 2, cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_title('REAIS', fontsize=12, loc='left')\n",
    "\n",
    "#imagens geradas\n",
    "noise = gerarRuido(8, latent_dim)\n",
    "gen_imgs = gerador.predict(noise, verbose=0)\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "for i in range(8):\n",
    "    axes[1, i].imshow(gen_imgs[i, :, :, 0], cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_title('GERADAS', fontsize=12, loc='left')\n",
    "\n",
    "plt.suptitle('Comparacao: Imagens Reais vs Geradas', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
